{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hatespeechdetection2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNGLuw4Fhrhw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTzfi8vbjkUm"
      },
      "source": [
        "data= pd.read_csv(\"tweets.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7ePEIATpthn"
      },
      "source": [
        "data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRWZ-Fzhsuv0"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuqHjyGZpy1T"
      },
      "source": [
        "data.drop(columns=['id'],axis=1,inplace=True)\n",
        "data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETx0i8Nup-30"
      },
      "source": [
        "#check the class  distribution\n",
        "data[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL7wfSCPrSUF"
      },
      "source": [
        "plt.bar([0,1],data[\"label\"].value_counts())\n",
        "plt.title(\"class proportions in the dataset\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAL41njCKYzY"
      },
      "source": [
        "dff = data.drop(['label'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaMYMrMTKL0w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(dff,list(data.label), test_size=0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vPU3A2ZN_i2"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt0ApiBQN_lv"
      },
      "source": [
        "X_temp['label'] = y_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRIYt9uiN_oF"
      },
      "source": [
        "\n",
        "X_temp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp1FEUn6N_q6"
      },
      "source": [
        "type(X_temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc510IcPN_tg"
      },
      "source": [
        "nonhate = X_temp[X_temp['label'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-jRmbX5N_wc"
      },
      "source": [
        "nonhate.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI8esMsbQ7Y2"
      },
      "source": [
        "hate = X_temp[X_temp.label == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LXoNxtWQ7eL"
      },
      "source": [
        "hate.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1cGRgC3Q7ic"
      },
      "source": [
        "nonhatesample = nonhate.sample(n = hate.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfsXDCxJQ7kn"
      },
      "source": [
        "nonhatesample.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryZzjKqXQ7nb"
      },
      "source": [
        "nonhatesample.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvqs-ctpQ7qK"
      },
      "source": [
        "ds = pd.concat([hate, nonhatesample], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55nrX-26Q7uC"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8x9p8soRlhm"
      },
      "source": [
        "testdf = X_test\n",
        "testdf['label'] = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95zYBtMrRlkQ"
      },
      "source": [
        "testdf.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGKoIh3FRlnG"
      },
      "source": [
        "\n",
        "ds = pd.concat([ds, testdf], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAGkMrvMRlqz"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40_Bf5OIRltE"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3YQTzM1U-64"
      },
      "source": [
        "#check the class  distribution\n",
        "ds[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPS8_WyU-92"
      },
      "source": [
        "plt.bar([0,1],ds[\"label\"].value_counts())\n",
        "plt.title(\"class proportions in the dataset\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5-Opdn7U_Mm"
      },
      "source": [
        "ds.to_csv(\"tweets.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDVjB6iCWFR8"
      },
      "source": [
        "ds = pd.read_csv(\"tweets.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jujMipSJWsFI"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4qMJoCCXOLv"
      },
      "source": [
        "#Code to remove @\n",
        "#ds['tweet'] = ds['tweet'].apply(lambda x : ' '.join([tweet for tweet in x.split()if not tweet.startswith(\"@\")]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eZw6plOXOOi"
      },
      "source": [
        "#ds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBGv_FnCXORV"
      },
      "source": [
        "#Removing numbers\n",
        "ds['tweet'] = ds['tweet'].apply(lambda x : ' '.join([tweet for tweet in x.split() if not tweet == '\\d*']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVDWBZ27X_n6"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nUECB30ZXiq"
      },
      "source": [
        "#removing # sign and &\n",
        "def clean(text):\n",
        "  text=re.sub(r\"#\",\" \",text)\n",
        "  text=re.sub(r\"&[a-z]+\",\" \",text)\n",
        "  text=re.sub(r\"@[a-zA-Z]+\",\" \",text )\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GON5_zY8ZYP0"
      },
      "source": [
        "ds[\"tweet\"]=ds[\"tweet\"].apply(clean)\n",
        "ds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek87aFDFxLR-"
      },
      "source": [
        "#Code for removing slang words\n",
        "d = {'luv':'love','wud':'would','lyk':'like','wateva':'whatever','ttyl':'talk to you later',\n",
        "               'kul':'cool','fyn':'fine','omg':'oh my god!','fam':'family','bruh':'brother',\n",
        "               'cud':'could','fud':'food'} ## Need a huge dictionary\n",
        "words = \"I luv kashmir\"\n",
        "words = words.split()\n",
        "reformed = [d[word] if word in d else word for word in words]\n",
        "reformed = \" \".join(reformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkRHrFb_6_Ia"
      },
      "source": [
        "reformed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSpCaQHh7DWR"
      },
      "source": [
        "ds['tweet'] = ds['tweet'].apply(lambda x : ' '.join(d[word] if word in d else word for word in x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx3fOlq67NNR"
      },
      "source": [
        "#Removing stopwords\n",
        "ds['tweet'] = ds['tweet'].apply(lambda x : ' '.join([word for word in x.split() if not word in set(stopwords.words('english'))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwke1jca9boG"
      },
      "source": [
        "ds.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvlcT3VdCtyt"
      },
      "source": [
        "#Stemming\n",
        "ps = PorterStemmer()\n",
        "ds['tweet'] = ds['tweet'].apply(lambda x : ' '.join([ps.stem(word) for word in x.split()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwbMOJMpsvOT"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlKbbO0bsxSy"
      },
      "source": [
        "ds.to_csv(\"tweets.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80BO0gO0f1CX"
      },
      "source": [
        "data=pd.read_csv(\"tweets.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2joqqYTf6cM"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJyym5iEf7-B"
      },
      "source": [
        "data=data.loc[:,[\"tweet\",\"label\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HdGO_B1iYQp"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRmYQVxUifTd"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "X = cv.fit_transform(data[\"tweet\"].values.astype('U')).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_QKgHm1jfIa"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XVRMTkZlFp5"
      },
      "source": [
        "from sklearn.metrics import f1_score , accuracy_score , confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,data[\"label\"],random_state=5, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRCssv7EmnHP"
      },
      "source": [
        "\n",
        "from sklearn.metrics import f1_score , accuracy_score , confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnSxQeokm8_o"
      },
      "source": [
        "#Training model using Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model= LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "pred= model.predict(X_test)\n",
        "\n",
        "log_f1=f1_score(y_test,pred)\n",
        "log_acc=accuracy_score(y_test,pred)\n",
        "log_con=confusion_matrix(y_test,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85lFBOUcpDhw"
      },
      "source": [
        " #Training model using Random Forest classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "randmodel=RandomForestClassifier()\n",
        "randmodel.fit(X_train,y_train)\n",
        "\n",
        "randpred=randmodel.predict(X_test)\n",
        "\n",
        "rand_f1=f1_score(randpred,y_test)\n",
        "rand_acc=accuracy_score(randpred,y_test)\n",
        "rand_con=confusion_matrix(y_test,randpred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LdKhhKdqDpf"
      },
      "source": [
        "# Training model using Naive bayes classifier\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detect_model = MultinomialNB()\n",
        "spam_detect_model.fit(X_train, y_train)\n",
        "\n",
        "mulpred=spam_detect_model.predict(X_test)\n",
        "\n",
        "mul_f1=f1_score(mulpred,y_test)\n",
        "mul_acc=accuracy_score(mulpred,y_test)\n",
        "mul_con=confusion_matrix(y_test,mulpred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojjEsb04L6Yo"
      },
      "source": [
        "# Training model using support vector machine\n",
        "\n",
        "from sklearn import svm\n",
        "clf=svm.SVC()\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "svmpred=clf.predict(X_test)\n",
        "\n",
        "svm_f1=f1_score(svmpred,y_test)\n",
        "svm_acc=accuracy_score(svmpred,y_test)\n",
        "svm_con=confusion_matrix(y_test,svmpred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpcw8So76Izj"
      },
      "source": [
        "import seaborn as sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMij-KJl6iNX"
      },
      "source": [
        "sn.heatmap(log_con)\n",
        "plt.title(\"Logistic Regression\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j9cpR_M7qFj"
      },
      "source": [
        "sn.heatmap(rand_con)\n",
        "plt.title(\"Random Forest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt_SsdBb7qQ2"
      },
      "source": [
        "sn.heatmap(mul_con)\n",
        "plt.title(\"Naive Bayes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRTfbjoZ7qYO"
      },
      "source": [
        "sn.heatmap(svm_con)\n",
        "plt.title(\"support vector machine\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAHGxBhN7qbT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUcZF25Vyu5u"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print('Logistic Regression Score: ', roc_auc_score(y_test, pred))\n",
        "print('Naive Bayes Score: ', roc_auc_score(y_test, mulpred))\n",
        "print('Random Forest Score: ', roc_auc_score(y_test, randpred))\n",
        "print('support vector machine score: ', roc_auc_score(y_test,svmpred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhN2mA8_NkBq"
      },
      "source": [
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "!pip install cartopy\n",
        "\n",
        "import cartopy\n",
        "import libarchive\n",
        "import pydot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "log_fpr, log_tpr, threshold = roc_curve(y_test,pred)\n",
        "nav_fpr, nav_tpr, threshold = roc_curve(y_test, mulpred )\n",
        "rand_fpr, rand_tpr, thresold = roc_curve(y_test, randpred)\n",
        "svm_fpr, svm_tpr, threshold = roc_curve(y_test,svmpred )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9C0Bs9a0nFC"
      },
      "source": [
        "def graph_roc_curve_multiple(rand_fpr, rand_tpr, nav_fpr, nav_tpr, log_fpr , log_tpr,svm_fpr, svm_tpr):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.title('ROC Curve \\n Classifiers', fontsize=18)\n",
        "    plt.plot(rand_fpr, rand_tpr, label='random forest')\n",
        "    plt.plot(nav_fpr, nav_tpr, label='Naive Bayes')\n",
        "    plt.plot(log_fpr, log_tpr, label='Logistic Regression')\n",
        "    plt.plot(svm_fpr, svm_tpr, label='svm')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
        "                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
        "                )\n",
        "    plt.legend()\n",
        "    \n",
        "graph_roc_curve_multiple(rand_fpr, rand_tpr, nav_fpr, nav_tpr, log_fpr, log_tpr,svm_fpr, svm_tpr )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIGyKj0z4QeJ"
      },
      "source": [
        "# Using term frequency _inverse document frequency\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5uomqjL9C6h"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(data[\"tweet\"].values.astype('U')).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Q7iXdH9C9V"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFL1lsl-9DAP"
      },
      "source": [
        "from sklearn.metrics import f1_score , accuracy_score , confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,data[\"label\"],random_state=5, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIVRa_nZ9DCn"
      },
      "source": [
        "#Training model using Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model= LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "pred= model.predict(X_test)\n",
        "\n",
        "log_f1=f1_score(y_test,pred)\n",
        "log_acc=accuracy_score(y_test,pred)\n",
        "log_con=confusion_matrix(y_test,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNpJDAD29zsq"
      },
      "source": [
        " #Training model using Random Forest classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "randmodel=RandomForestClassifier()\n",
        "randmodel.fit(X_train,y_train)\n",
        "\n",
        "randpred=randmodel.predict(X_test)\n",
        "\n",
        "rand_f1=f1_score(randpred,y_test)\n",
        "rand_acc=accuracy_score(randpred,y_test)\n",
        "rand_con=confusion_matrix(y_test,randpred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTnUykn79zvf"
      },
      "source": [
        "# Training model using Naive bayes classifier\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detect_model = MultinomialNB()\n",
        "spam_detect_model.fit(X_train, y_train)\n",
        "\n",
        "mulpred=spam_detect_model.predict(X_test)\n",
        "\n",
        "mul_f1=f1_score(mulpred,y_test)\n",
        "mul_acc=accuracy_score(mulpred,y_test)\n",
        "mul_con=confusion_matrix(y_test,mulpred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k93PN0y2960q"
      },
      "source": [
        "# Training model using support vector machine\n",
        "\n",
        "from sklearn import svm\n",
        "clf=svm.SVC()\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "svmpred=clf.predict(X_test)\n",
        "\n",
        "svm_f1=f1_score(svmpred,y_test)\n",
        "svm_acc=accuracy_score(svmpred,y_test)\n",
        "svm_con=confusion_matrix(y_test,svmpred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t15gkHM963R"
      },
      "source": [
        "import seaborn as sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO6Mric5966I"
      },
      "source": [
        "sn.heatmap(log_con)\n",
        "plt.title(\"Logistic Regression\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8W9bo_v968l"
      },
      "source": [
        "sn.heatmap(rand_con)\n",
        "plt.title(\"Random Forest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MlcFMva96_g"
      },
      "source": [
        "sn.heatmap(mul_con)\n",
        "plt.title(\"Naive Bayes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKfCsvPw97By"
      },
      "source": [
        "sn.heatmap(svm_con)\n",
        "plt.title(\"support vector machine\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6sLPjvO9zyM"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print('Logistic Regression Score: ', roc_auc_score(y_test, pred))\n",
        "print('Naive Bayes Score: ', roc_auc_score(y_test, mulpred))\n",
        "print('Random Forest Score: ', roc_auc_score(y_test, randpred))\n",
        "print('support vector machine score: ', roc_auc_score(y_test,svmpred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmELzklH-LUq"
      },
      "source": [
        "import cartopy\n",
        "import libarchive\n",
        "import pydot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "log_fpr, log_tpr, threshold = roc_curve(y_test,pred)\n",
        "nav_fpr, nav_tpr, threshold = roc_curve(y_test, mulpred )\n",
        "rand_fpr, rand_tpr, thresold = roc_curve(y_test, randpred)\n",
        "svm_fpr, svm_tpr, threshold = roc_curve(y_test,svmpred )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HscKksnU-LX0"
      },
      "source": [
        "def graph_roc_curve_multiple(rand_fpr, rand_tpr, nav_fpr, nav_tpr, log_fpr , log_tpr,svm_fpr, svm_tpr):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.title('ROC Curve \\n Classifiers', fontsize=18)\n",
        "    plt.plot(rand_fpr, rand_tpr, label='random forest')\n",
        "    plt.plot(nav_fpr, nav_tpr, label='Naive Bayes')\n",
        "    plt.plot(log_fpr, log_tpr, label='Logistic Regression')\n",
        "    plt.plot(svm_fpr, svm_tpr, label='svm')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
        "                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
        "                )\n",
        "    plt.legend()\n",
        "    \n",
        "graph_roc_curve_multiple(rand_fpr, rand_tpr, nav_fpr, nav_tpr, log_fpr, log_tpr,svm_fpr, svm_tpr )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bFxoYm6-LbQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}